{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup\n",
    "import requests # Импортируем библиотеку requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска необходимых нам данных мы будем использовать библиотеку BeautifulSoup, которая позволяет по названию тегов и их атрибутов получать содержащийся в них текст.\n",
    "\n",
    "BeautifulSoup не является частью стандартной библиотеки, поэтому для начала её нужно установить. Например, в Jupyter Notebook это делается с помощью такой команды:\n",
    "\n",
    "# Устанавливаем библиотеку BeautifulSoup\n",
    "!pip install beautifulsoup4 \n",
    "После установки импортируем библиотеку в наш код:\n",
    "\n",
    "from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем извлекать данные из любой веб-страницы.\n",
    "\n",
    "Ранее мы уже получили содержимое страницы с помощью GET-запроса и сохранили информацию в переменной response , теперь создадим объект BeautifulSoup с именем page, указывая в качестве параметра html.parser.\n",
    "\n",
    "Для примера получим информацию o title (с англ. заголовок) — это строка, которая отображается на вкладке браузера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей</title>\n",
      "Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n"
     ]
    }
   ],
   "source": [
    "url = 'https://nplus1.ru/news/2021/10/11/econobel2021' # Определяем адрес страницы\n",
    "response = requests.get(url)\n",
    "page = BeautifulSoup(response.text, 'html.parser')\n",
    "print(page.title) # Получаем тег title, отображающийся на вкладке браузера\n",
    "print(page.title.text) # Выводим текст из полученного тега, который содержится в атрибуте text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если при запросе к сайту, а затем при его разборе с помощью BeautifulSoup в тексте страницы не находится нужный тег, попробуйте вывести на печать пару тысяч символов текста страницы. Если там обнаружится нечто похожее на капчу, возможно, сайт посчитал вас роботом и отказывается выдавать содержимое. Чтобы получить его, попробуйте «притвориться» браузером при запросе из скрипта:\n",
    "\n",
    "requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "User-Agent своего браузера можно узнать по этой ссылке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИЗВЛЕКАЕМ ЗАГОЛОВОК СТАТЬИ\n",
    "\n",
    "Выполним поставленную ранее задачу: получить информацию о странице и извлечь заголовок статьи, опубликованной на этой странице, дату публикации, а также текст статьи.\n",
    "\n",
    "Предположим, что мы знаем, что в HTML-коде рассматриваемой нами страницы заголовок статьи заключён в тег <h1> … </h1> (заголовок первого уровня).\n",
    "\n",
    "Тогда мы можем получить его текст с помощью метода find() (с англ. найти) объекта BeautifulSoup, передав ему название интересующего нас тега:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# Применяем метод find() к объекту и выводим результат на экран\n",
    "print(page.find('h1').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "о как же узнать, в каких именно тегах заключена необходимая информация?\n",
    "\n",
    "Проще всего это сделать с помощью так называемого инструмента разработчика, который есть во всех современных браузерах. Покажем, как открыть данный инструмент на примере использования браузера Google Chrome.\n",
    "\n",
    "Устанавливаем курсор на элементе страницы (заголовок статьи), информацию о котором хотим получить, нажимаем на правую клавишу мыши и в выпадающем списке выбираем пункт «Просмотреть код элемента» или «Исследовать» в зависимости от браузера.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "НЕУНИКАЛЬНЫЕ ТЕГИ: ИЗВЛЕКАЕМ ТЕКСТ И ДАТУ ПУБЛИКАЦИИ СТАТЬИ\n",
    "\n",
    "Теперь получим сам текст статьи. Как вы уже знаете, первым делом необходимо определить, в какой тег он заключён. Применим, как и ранее, инструмент разработчика.\n",
    "\n",
    "\n",
    "\n",
    "Видим, что искомый текст заключён в тег  <div> … </div> . Попробуем извлечь его уже известным нам способом — с помощью метода find() — и выведем его на экран.\n",
    "\n",
    "print(page.find('div').text) # Выводим содержимое атрибута text тега div\n",
    "Мы увидели не то, что ожидали — кучу текста, не имеющего отношения к тому, что мы искали...\n",
    "\n",
    "?\n",
    "В чём же проблема?\n",
    "\n",
    "Дело в том, что теги <div> … </div> очень распространённые и на странице их очень много. Метод find() нашёл первый из них, но это не то, что нам надо.\n",
    "\n",
    "Посмотрим на нашу страницу, используя инструмент разработчика, ещё раз. Можем заметить, что у искомого текста есть свой класс — n1_material text-18 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим название класса в метод find() с помощью аргумента class_ и получим текст статьи:\n",
    "\n",
    "print(page.find('div', class_='n1_material text-18').text) # Выводим содержимое атрибута text тега div класса n1_material text-18\n",
    "\n",
    "\n",
    "В данном случае происходит поиск точного строкового значения class атрибута, т. е. выполнение строк кода:\n",
    "\n",
    "print(page.find('div', class_='n1_material').text)\n",
    "print(page.find('div', class_='n1_material text-18').text)\n",
    "даст одинаковый результат.\n",
    "\n",
    "При выполнении строки кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(page.find('div', class_='text-18 n1_material').text)\n",
    "мы получим ошибку, так как такого строкового значения в области поиска нет.\n",
    "\n",
    "Аналогично получим информации о теге, который содержит дату написания статьи, отображаемую в левом верхнем углу страницы.\n",
    "\n",
    "\n",
    "\n",
    "Итак, нам нужен тег <a> … </a> с классом \"relative before:block before:w-px before:bg-current before:h-4 before:absolute before:left-0 group pl-2 flex inline-flex items-center\". Для поиска достаточно указать в качестве класса \"relative\", отбросив дополнительные настройки.\n",
    "\n",
    "Теперь получим данные из него с помощью уже известного метода find(), передав название нужного тега:\n",
    "\n",
    "# Выводим на экран содержимое атрибута text тега a с классом \"relative\"\n",
    "print(page.find('a', class_= \"relative\").text)\n",
    "\n",
    "\n",
    "О поиске по классу можно узнать подробнее в Beautiful Soup Documentation.\n",
    "\n",
    "Задача решена — мы извлекли из контента страницы заголовок статьи, опубликованной на странице, дату публикации, а также текст статьи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СБОР НЕСКОЛЬКИХ ЭЛЕМЕНТОВ: СОБИРАЕМ ВСЕ ССЫЛКИ НА СТРАНИЦЕ\n",
    "\n",
    "Рассмотрим ещё один сценарий: вы хотите собрать сразу несколько элементов со страницы. Например, представьте, что вы хотите получить названия всех языков программирования, упомянутых на странице в Wikipedia в статье про языки программирования.\n",
    "\n",
    "Можно заметить, что все названия языков программирования на этой странице связаны ссылками c соответствующими статьями о них. Таким образом, нам необходимо собрать все ссылки на странице. Для ссылок в HTML предусмотрен тег <a> … </a>. Попробуем использовать find():\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_programming_languages' # Задаём адрес ресурса\n",
    "response = requests.get(url) # Делаем GET-запрос к ресурсу\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup\n",
    "print(page.find('a')) # Ищем ссылку по тегу <a> и выводим её на экран\n",
    "\n",
    "\n",
    "Мы получили только одну ссылку, хотя на странице их явно больше.\n",
    "\n",
    "Это происходит, потому что метод find() возвращает только первый подходящий элемент. Если требуется получить больше элементов, необходимо воспользоваться методом find_all() (с англ. найти все):\n",
    "\n",
    "links = page.find_all('a') # Ищем все ссылки на странице и сохраняем в переменной links в виде списка\n",
    "print(len(links)) # Выводим количество найденных ссылок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, на момент создания этих учебных материалов на странице содержалось 928 ссылок. Посмотрим на некоторые из них:\n",
    "\n",
    "print([link.text for link in links[500:510]]) # Выводим ссылки с 500 по 509 включительно\n",
    "\n",
    "\n",
    "Не все ссылки соответствуют названиям языков программирования — страница содержит также «служебные» ссылки, такие, например, как Jump to navigation (с англ. Перейти к навигации) или Alphabetical (с англ. По алфавиту):\n",
    "\n",
    "print([link.text for link in links[0:10]]) # Выводим ссылки с 1 по 9 включительно\n",
    "\n",
    "\n",
    "Для обработки полученных данных и исключения «лишней» информации можно, например, использовать подходы, которые вы изучили в модуле PYTHON-14.\n",
    "\n",
    "✍ В заключение заметим, что BeautifulSoup — достаточно мощная библиотека. Мы рассмотрели её базовые возможности, но их полный список гораздо шире. С ним можно ознакомиться в официальной документации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
